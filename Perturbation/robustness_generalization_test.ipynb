{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQZssIo1a3FU",
        "outputId": "e74e24a7-a0a5-4808-e5fe-9a3bb5ad3564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_scatter, pyg_lib, torch_sparse\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import ModuleList\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import HypergraphConv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NvMOVZ-Ga4bI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-hop 하이퍼엣지 생성\n",
        "def generate_1hop_hyperedge_index(data):\n",
        "    edge_index = data.edge_index\n",
        "    num_nodes = data.num_nodes\n",
        "    edge_dict = defaultdict(set)\n",
        "\n",
        "    # 1-hop 이웃 관계 구성 (양방향으로 간주)\n",
        "    for src, tgt in edge_index.t().tolist():\n",
        "        edge_dict[src].add(tgt)\n",
        "        edge_dict[tgt].add(src)\n",
        "\n",
        "    # hyperedge 생성: 각 노드 + 그 이웃들 = 하나의 hyperedge\n",
        "    node_list = []\n",
        "    hyperedge_list = []\n",
        "    for hyperedge_id, node in enumerate(range(num_nodes)):\n",
        "        group = edge_dict[node] | {node}  # 자신 포함\n",
        "        for n in group:\n",
        "            node_list.append(n)\n",
        "            hyperedge_list.append(hyperedge_id)\n",
        "\n",
        "    hyperedge_index = torch.tensor([node_list, hyperedge_list], dtype=torch.long)\n",
        "    return hyperedge_index"
      ],
      "metadata": {
        "id": "8zjWkYkN9qbu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gaussian noise\n",
        "def add_gaussian_noise(data, sigma=0.1, seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    noise = torch.randn_like(data.x) * sigma\n",
        "    data_noisy = data.clone()\n",
        "    data_noisy.x = data.x + noise\n",
        "    return data_noisy\n",
        "\n",
        "# perturbation\n",
        "def perturb_edges(data, perturb_ratio=0.05, seed=42):\n",
        "    random.seed(seed)\n",
        "    num_edges = data.edge_index.size(1)\n",
        "    num_nodes = data.num_nodes\n",
        "    data_perturbed = data.clone()\n",
        "\n",
        "    # edge 삭제\n",
        "    num_remove = int(num_edges * perturb_ratio)\n",
        "    edge_indices = list(range(num_edges))\n",
        "    remove_indices = random.sample(edge_indices, num_remove)\n",
        "\n",
        "    mask = torch.ones(num_edges, dtype=torch.bool)\n",
        "    mask[remove_indices] = False\n",
        "    data_perturbed.edge_index = data.edge_index[:, mask]\n",
        "\n",
        "    # edge 추가\n",
        "    num_add = num_remove  # 삭제 수 == 추가 수\n",
        "    added_edges = []\n",
        "    while len(added_edges) < num_add:\n",
        "        u = random.randint(0, num_nodes - 1)\n",
        "        v = random.randint(0, num_nodes - 1)\n",
        "        if u == v:\n",
        "            continue\n",
        "        # 중복 방지\n",
        "        if ((data_perturbed.edge_index[0] == u) & (data_perturbed.edge_index[1] == v)).any():\n",
        "            continue\n",
        "        added_edges.append([u, v])\n",
        "        added_edges.append([v, u])  # 무방향 그래프 가정\n",
        "\n",
        "    if added_edges:\n",
        "        added_edges = torch.tensor(added_edges).t().contiguous()\n",
        "        data_perturbed.edge_index = torch.cat([data_perturbed.edge_index, added_edges], dim=1)\n",
        "\n",
        "    return data_perturbed\n",
        "\n",
        "# label noise\n",
        "def add_label_noise(data, noise_ratio=0.1, seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    data_noisy = data.clone()\n",
        "    num_nodes = data.y.size(0)\n",
        "    num_noisy = int(num_nodes * noise_ratio)\n",
        "\n",
        "    all_indices = torch.randperm(num_nodes)\n",
        "    noisy_indices = all_indices[:num_noisy]\n",
        "\n",
        "    num_classes = int(data.y.max().item() + 1)\n",
        "    for idx in noisy_indices:\n",
        "        original_label = data_noisy.y[idx].item()\n",
        "        new_label = random.choice([c for c in range(num_classes) if c != original_label])\n",
        "        data_noisy.y[idx] = new_label\n",
        "\n",
        "    return data_noisy"
      ],
      "metadata": {
        "id": "VeDhoUPfbrsf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset: Cora, Citeseer, Pubmed\n",
        "normalize = NormalizeFeatures()\n",
        "datasets = {}\n",
        "\n",
        "# 원본, gaussain noise, perturbation, label noise\n",
        "augmentations = {\n",
        "    \"\": lambda d: d,  # 원본\n",
        "    \"_gaussiannoise\": lambda d: add_gaussian_noise(d.clone(), sigma=0.1),\n",
        "    \"_perturbation\": lambda d: perturb_edges(d.clone(), perturb_ratio=0.05),\n",
        "    \"_labelnoise\": lambda d: add_label_noise(d.clone(), noise_ratio=0.05),\n",
        "}\n",
        "\n",
        "planetoid_names = ['Cora', 'Citeseer', 'Pubmed']\n",
        "\n",
        "for name in planetoid_names:\n",
        "    base_data = Planetoid(root=f'data/{name}', name=name, transform=normalize)[0]\n",
        "\n",
        "    for suffix, aug_func in augmentations.items():\n",
        "        data_aug = aug_func(base_data)\n",
        "        data_aug.hyperedge_index = generate_1hop_hyperedge_index(data_aug)\n",
        "        datasets[name + suffix] = data_aug"
      ],
      "metadata": {
        "id": "Bd7D7LC6nsru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6438c89f-87e1-498d-b87e-f36c8fa3af29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hypergraph 정보\n",
        "def summarize_hypergraph(data):\n",
        "    if not hasattr(data, 'hyperedge_index'):\n",
        "        return \"No hyperedge_index\"\n",
        "\n",
        "    he = data.hyperedge_index\n",
        "    num_nodes = data.num_nodes\n",
        "    num_hyperedges = he[1].max().item() + 1 if he.numel() > 0 else 0\n",
        "\n",
        "    # 각 하이퍼엣지가 연결한 노드 수\n",
        "    edge_sizes = Counter(he[1].tolist())\n",
        "    avg_size = sum(edge_sizes.values()) / len(edge_sizes) if edge_sizes else 0\n",
        "\n",
        "    return f\"{num_hyperedges} hyperedges, {avg_size:.2f} avg size\"\n",
        "\n",
        "# dataset 정보\n",
        "for name, data in datasets.items():\n",
        "    print(f\"\\n Dataset: {name}\")\n",
        "    print(f\" - Nodes         : {data.num_nodes}\")\n",
        "    print(f\" - Edges         : {data.num_edges}\")\n",
        "    print(f\" - Features      : {data.num_node_features}\")\n",
        "    print(f\" - Classes       : {data.y.unique().numel()}\")\n",
        "    print(f\" - Hypergraph    : {summarize_hypergraph(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in6wYLzo-b7t",
        "outputId": "0bcbeb76-96ee-4f17-93c3-8504464b0b63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset: Cora\n",
            " - Nodes         : 2708\n",
            " - Edges         : 10556\n",
            " - Features      : 1433\n",
            " - Classes       : 7\n",
            " - Hypergraph    : 2708 hyperedges, 4.90 avg size\n",
            "\n",
            " Dataset: Cora_gaussiannoise\n",
            " - Nodes         : 2708\n",
            " - Edges         : 10556\n",
            " - Features      : 1433\n",
            " - Classes       : 7\n",
            " - Hypergraph    : 2708 hyperedges, 4.90 avg size\n",
            "\n",
            " Dataset: Cora_perturbation\n",
            " - Nodes         : 2708\n",
            " - Edges         : 10557\n",
            " - Features      : 1433\n",
            " - Classes       : 7\n",
            " - Hypergraph    : 2708 hyperedges, 5.09 avg size\n",
            "\n",
            " Dataset: Cora_labelnoise\n",
            " - Nodes         : 2708\n",
            " - Edges         : 10556\n",
            " - Features      : 1433\n",
            " - Classes       : 7\n",
            " - Hypergraph    : 2708 hyperedges, 4.90 avg size\n",
            "\n",
            " Dataset: Citeseer\n",
            " - Nodes         : 3327\n",
            " - Edges         : 9104\n",
            " - Features      : 3703\n",
            " - Classes       : 6\n",
            " - Hypergraph    : 3327 hyperedges, 3.74 avg size\n",
            "\n",
            " Dataset: Citeseer_gaussiannoise\n",
            " - Nodes         : 3327\n",
            " - Edges         : 9104\n",
            " - Features      : 3703\n",
            " - Classes       : 6\n",
            " - Hypergraph    : 3327 hyperedges, 3.74 avg size\n",
            "\n",
            " Dataset: Citeseer_perturbation\n",
            " - Nodes         : 3327\n",
            " - Edges         : 9105\n",
            " - Features      : 3703\n",
            " - Classes       : 6\n",
            " - Hypergraph    : 3327 hyperedges, 3.87 avg size\n",
            "\n",
            " Dataset: Citeseer_labelnoise\n",
            " - Nodes         : 3327\n",
            " - Edges         : 9104\n",
            " - Features      : 3703\n",
            " - Classes       : 6\n",
            " - Hypergraph    : 3327 hyperedges, 3.74 avg size\n",
            "\n",
            " Dataset: Pubmed\n",
            " - Nodes         : 19717\n",
            " - Edges         : 88648\n",
            " - Features      : 500\n",
            " - Classes       : 3\n",
            " - Hypergraph    : 19717 hyperedges, 5.50 avg size\n",
            "\n",
            " Dataset: Pubmed_gaussiannoise\n",
            " - Nodes         : 19717\n",
            " - Edges         : 88648\n",
            " - Features      : 500\n",
            " - Classes       : 3\n",
            " - Hypergraph    : 19717 hyperedges, 5.50 avg size\n",
            "\n",
            " Dataset: Pubmed_perturbation\n",
            " - Nodes         : 19717\n",
            " - Edges         : 88648\n",
            " - Features      : 500\n",
            " - Classes       : 3\n",
            " - Hypergraph    : 19717 hyperedges, 5.71 avg size\n",
            "\n",
            " Dataset: Pubmed_labelnoise\n",
            " - Nodes         : 19717\n",
            " - Edges         : 88648\n",
            " - Features      : 500\n",
            " - Classes       : 3\n",
            " - Hypergraph    : 19717 hyperedges, 5.50 avg size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GCN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels=16, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.convs = ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = F.relu(conv(x, edge_index))\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.convs[-1](x, edge_index)\n",
        "\n",
        "    def get_hidden_embeddings(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = F.relu(conv(x, edge_index))\n",
        "            x = F.dropout(x, p=self.dropout, training=False)\n",
        "        return x\n",
        "\n",
        "# HyperGCN\n",
        "class HyperGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels=16, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.convs = ModuleList()\n",
        "        self.convs.append(HypergraphConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(HypergraphConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(HypergraphConv(hidden_channels, out_channels))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, hyperedge_index = data.x, data.hyperedge_index\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = F.relu(conv(x, hyperedge_index))\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.convs[-1](x, hyperedge_index)\n",
        "\n",
        "    def get_hidden_embeddings(self, data):\n",
        "        x, hyperedge_index = data.x, data.hyperedge_index\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = F.relu(conv(x, hyperedge_index))\n",
        "            x = F.dropout(x, p=self.dropout, training=False)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SaKII9UxvK0P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test\n",
        "def train(model, data, optimizer, epoch=None):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch is not None and epoch % 10 == 0:\n",
        "        print(f\"[Epoch {epoch:>3}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    out = model(data)\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = out[mask].argmax(dim=1)\n",
        "        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs"
      ],
      "metadata": {
        "id": "MHYIrYvNvMCn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training, validation, test\n",
        "def run_experiment(name=\"Cora\", model_class=GCN, epochs=200, lr=0.01, weight_decay=5e-4, verbose=False):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    data = datasets[name].to(device)\n",
        "\n",
        "    num_features = data.num_features\n",
        "    num_classes = data.y.unique().numel()\n",
        "\n",
        "    model = model_class(num_features, num_classes).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    test_acc_at_best_val = 0.0\n",
        "    final_train_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, data, optimizer, epoch if verbose else None)\n",
        "        accs = test(model, data)\n",
        "        train_acc, val_acc, test_acc = accs\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc_at_best_val = test_acc\n",
        "            final_train_acc = train_acc\n",
        "\n",
        "        if verbose and epoch % 10 == 0:\n",
        "            print(f\"[Epoch {epoch:>3}] Val Acc: {val_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_class.__name__,\n",
        "        \"Dataset\": name,\n",
        "        \"Train Acc @ Best Val\": final_train_acc,\n",
        "        \"Best Val Acc\": best_val_acc,\n",
        "        \"Test Acc @ Best Val\": test_acc_at_best_val\n",
        "    }"
      ],
      "metadata": {
        "id": "RTozpbRzxC_O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행\n",
        "def run_all_experiments(model_classes=[GCN, HyperGCN], dataset_dict=datasets, verbose=False):\n",
        "    results = []\n",
        "\n",
        "    for model_cls in model_classes:\n",
        "        for name in dataset_dict.keys():\n",
        "            print(f\"\\n---------- {model_cls.__name__} | {name} ----------\")\n",
        "            result = run_experiment(name=name, model_class=model_cls, verbose=verbose)\n",
        "            results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# 결과 저장 및 출력\n",
        "df = run_all_experiments(verbose=True)\n",
        "print(\"Final Results:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdrU5j-ix74b",
        "outputId": "550ee4ed-2790-4d3e-8fae-48a57918f97b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------- GCN | Cora ----------\n",
            "[Epoch  10] Loss: 1.8494\n",
            "[Epoch  10] Val Acc: 0.6420 | Test Acc: 0.6860\n",
            "[Epoch  20] Loss: 1.6934\n",
            "[Epoch  20] Val Acc: 0.6860 | Test Acc: 0.7110\n",
            "[Epoch  30] Loss: 1.5202\n",
            "[Epoch  30] Val Acc: 0.7240 | Test Acc: 0.7600\n",
            "[Epoch  40] Loss: 1.3259\n",
            "[Epoch  40] Val Acc: 0.7300 | Test Acc: 0.7700\n",
            "[Epoch  50] Loss: 1.1503\n",
            "[Epoch  50] Val Acc: 0.7660 | Test Acc: 0.7980\n",
            "[Epoch  60] Loss: 0.9695\n",
            "[Epoch  60] Val Acc: 0.7740 | Test Acc: 0.7950\n",
            "[Epoch  70] Loss: 0.8752\n",
            "[Epoch  70] Val Acc: 0.7720 | Test Acc: 0.7980\n",
            "[Epoch  80] Loss: 0.7267\n",
            "[Epoch  80] Val Acc: 0.7780 | Test Acc: 0.8110\n",
            "[Epoch  90] Loss: 0.6984\n",
            "[Epoch  90] Val Acc: 0.7820 | Test Acc: 0.8140\n",
            "[Epoch 100] Loss: 0.6075\n",
            "[Epoch 100] Val Acc: 0.7860 | Test Acc: 0.8160\n",
            "[Epoch 110] Loss: 0.5659\n",
            "[Epoch 110] Val Acc: 0.7800 | Test Acc: 0.8100\n",
            "[Epoch 120] Loss: 0.4933\n",
            "[Epoch 120] Val Acc: 0.7820 | Test Acc: 0.8140\n",
            "[Epoch 130] Loss: 0.4701\n",
            "[Epoch 130] Val Acc: 0.7940 | Test Acc: 0.8130\n",
            "[Epoch 140] Loss: 0.4784\n",
            "[Epoch 140] Val Acc: 0.7900 | Test Acc: 0.8220\n",
            "[Epoch 150] Loss: 0.4822\n",
            "[Epoch 150] Val Acc: 0.7940 | Test Acc: 0.8190\n",
            "[Epoch 160] Loss: 0.3765\n",
            "[Epoch 160] Val Acc: 0.7940 | Test Acc: 0.8160\n",
            "[Epoch 170] Loss: 0.3531\n",
            "[Epoch 170] Val Acc: 0.7920 | Test Acc: 0.8170\n",
            "[Epoch 180] Loss: 0.3886\n",
            "[Epoch 180] Val Acc: 0.7960 | Test Acc: 0.8260\n",
            "[Epoch 190] Loss: 0.3343\n",
            "[Epoch 190] Val Acc: 0.7940 | Test Acc: 0.8200\n",
            "[Epoch 200] Loss: 0.3924\n",
            "[Epoch 200] Val Acc: 0.7960 | Test Acc: 0.8200\n",
            "\n",
            "---------- GCN | Cora_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 1.1590\n",
            "[Epoch  10] Val Acc: 0.4600 | Test Acc: 0.4490\n",
            "[Epoch  20] Loss: 0.4445\n",
            "[Epoch  20] Val Acc: 0.4880 | Test Acc: 0.4860\n",
            "[Epoch  30] Loss: 0.1726\n",
            "[Epoch  30] Val Acc: 0.5080 | Test Acc: 0.5010\n",
            "[Epoch  40] Loss: 0.0889\n",
            "[Epoch  40] Val Acc: 0.5260 | Test Acc: 0.5140\n",
            "[Epoch  50] Loss: 0.0556\n",
            "[Epoch  50] Val Acc: 0.5300 | Test Acc: 0.5200\n",
            "[Epoch  60] Loss: 0.0571\n",
            "[Epoch  60] Val Acc: 0.5340 | Test Acc: 0.5230\n",
            "[Epoch  70] Loss: 0.0537\n",
            "[Epoch  70] Val Acc: 0.5300 | Test Acc: 0.5290\n",
            "[Epoch  80] Loss: 0.0565\n",
            "[Epoch  80] Val Acc: 0.5400 | Test Acc: 0.5260\n",
            "[Epoch  90] Loss: 0.0588\n",
            "[Epoch  90] Val Acc: 0.5440 | Test Acc: 0.5280\n",
            "[Epoch 100] Loss: 0.0491\n",
            "[Epoch 100] Val Acc: 0.5420 | Test Acc: 0.5290\n",
            "[Epoch 110] Loss: 0.0615\n",
            "[Epoch 110] Val Acc: 0.5420 | Test Acc: 0.5320\n",
            "[Epoch 120] Loss: 0.0623\n",
            "[Epoch 120] Val Acc: 0.5580 | Test Acc: 0.5450\n",
            "[Epoch 130] Loss: 0.0488\n",
            "[Epoch 130] Val Acc: 0.5540 | Test Acc: 0.5350\n",
            "[Epoch 140] Loss: 0.0249\n",
            "[Epoch 140] Val Acc: 0.5480 | Test Acc: 0.5420\n",
            "[Epoch 150] Loss: 0.0489\n",
            "[Epoch 150] Val Acc: 0.5480 | Test Acc: 0.5430\n",
            "[Epoch 160] Loss: 0.0467\n",
            "[Epoch 160] Val Acc: 0.5560 | Test Acc: 0.5430\n",
            "[Epoch 170] Loss: 0.0517\n",
            "[Epoch 170] Val Acc: 0.5420 | Test Acc: 0.5410\n",
            "[Epoch 180] Loss: 0.0507\n",
            "[Epoch 180] Val Acc: 0.5440 | Test Acc: 0.5420\n",
            "[Epoch 190] Loss: 0.0395\n",
            "[Epoch 190] Val Acc: 0.5500 | Test Acc: 0.5460\n",
            "[Epoch 200] Loss: 0.0419\n",
            "[Epoch 200] Val Acc: 0.5500 | Test Acc: 0.5400\n",
            "\n",
            "---------- GCN | Cora_perturbation ----------\n",
            "[Epoch  10] Loss: 1.8759\n",
            "[Epoch  10] Val Acc: 0.5040 | Test Acc: 0.5550\n",
            "[Epoch  20] Loss: 1.7458\n",
            "[Epoch  20] Val Acc: 0.6400 | Test Acc: 0.6790\n",
            "[Epoch  30] Loss: 1.5911\n",
            "[Epoch  30] Val Acc: 0.6760 | Test Acc: 0.7300\n",
            "[Epoch  40] Loss: 1.3836\n",
            "[Epoch  40] Val Acc: 0.7060 | Test Acc: 0.7510\n",
            "[Epoch  50] Loss: 1.2280\n",
            "[Epoch  50] Val Acc: 0.7240 | Test Acc: 0.7540\n",
            "[Epoch  60] Loss: 1.0689\n",
            "[Epoch  60] Val Acc: 0.7300 | Test Acc: 0.7680\n",
            "[Epoch  70] Loss: 0.9409\n",
            "[Epoch  70] Val Acc: 0.7440 | Test Acc: 0.7740\n",
            "[Epoch  80] Loss: 0.8241\n",
            "[Epoch  80] Val Acc: 0.7600 | Test Acc: 0.7910\n",
            "[Epoch  90] Loss: 0.7365\n",
            "[Epoch  90] Val Acc: 0.7600 | Test Acc: 0.7890\n",
            "[Epoch 100] Loss: 0.6776\n",
            "[Epoch 100] Val Acc: 0.7680 | Test Acc: 0.7900\n",
            "[Epoch 110] Loss: 0.5865\n",
            "[Epoch 110] Val Acc: 0.7700 | Test Acc: 0.7910\n",
            "[Epoch 120] Loss: 0.5394\n",
            "[Epoch 120] Val Acc: 0.7720 | Test Acc: 0.7940\n",
            "[Epoch 130] Loss: 0.5189\n",
            "[Epoch 130] Val Acc: 0.7720 | Test Acc: 0.7880\n",
            "[Epoch 140] Loss: 0.4711\n",
            "[Epoch 140] Val Acc: 0.7720 | Test Acc: 0.7940\n",
            "[Epoch 150] Loss: 0.4867\n",
            "[Epoch 150] Val Acc: 0.7720 | Test Acc: 0.7960\n",
            "[Epoch 160] Loss: 0.4050\n",
            "[Epoch 160] Val Acc: 0.7740 | Test Acc: 0.7980\n",
            "[Epoch 170] Loss: 0.4233\n",
            "[Epoch 170] Val Acc: 0.7720 | Test Acc: 0.7960\n",
            "[Epoch 180] Loss: 0.3703\n",
            "[Epoch 180] Val Acc: 0.7760 | Test Acc: 0.7950\n",
            "[Epoch 190] Loss: 0.3958\n",
            "[Epoch 190] Val Acc: 0.7760 | Test Acc: 0.7960\n",
            "[Epoch 200] Loss: 0.3205\n",
            "[Epoch 200] Val Acc: 0.7680 | Test Acc: 0.7900\n",
            "\n",
            "---------- GCN | Cora_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.8637\n",
            "[Epoch  10] Val Acc: 0.1340 | Test Acc: 0.1480\n",
            "[Epoch  20] Loss: 1.7303\n",
            "[Epoch  20] Val Acc: 0.3000 | Test Acc: 0.3140\n",
            "[Epoch  30] Loss: 1.5487\n",
            "[Epoch  30] Val Acc: 0.4820 | Test Acc: 0.4760\n",
            "[Epoch  40] Loss: 1.3362\n",
            "[Epoch  40] Val Acc: 0.6440 | Test Acc: 0.6530\n",
            "[Epoch  50] Loss: 1.1636\n",
            "[Epoch  50] Val Acc: 0.6840 | Test Acc: 0.6810\n",
            "[Epoch  60] Loss: 1.0078\n",
            "[Epoch  60] Val Acc: 0.7100 | Test Acc: 0.7190\n",
            "[Epoch  70] Loss: 0.8773\n",
            "[Epoch  70] Val Acc: 0.7360 | Test Acc: 0.7340\n",
            "[Epoch  80] Loss: 0.7592\n",
            "[Epoch  80] Val Acc: 0.7380 | Test Acc: 0.7370\n",
            "[Epoch  90] Loss: 0.6635\n",
            "[Epoch  90] Val Acc: 0.7480 | Test Acc: 0.7500\n",
            "[Epoch 100] Loss: 0.5960\n",
            "[Epoch 100] Val Acc: 0.7360 | Test Acc: 0.7450\n",
            "[Epoch 110] Loss: 0.5403\n",
            "[Epoch 110] Val Acc: 0.7480 | Test Acc: 0.7480\n",
            "[Epoch 120] Loss: 0.5269\n",
            "[Epoch 120] Val Acc: 0.7500 | Test Acc: 0.7520\n",
            "[Epoch 130] Loss: 0.4709\n",
            "[Epoch 130] Val Acc: 0.7500 | Test Acc: 0.7450\n",
            "[Epoch 140] Loss: 0.4476\n",
            "[Epoch 140] Val Acc: 0.7480 | Test Acc: 0.7450\n",
            "[Epoch 150] Loss: 0.4264\n",
            "[Epoch 150] Val Acc: 0.7460 | Test Acc: 0.7440\n",
            "[Epoch 160] Loss: 0.4241\n",
            "[Epoch 160] Val Acc: 0.7460 | Test Acc: 0.7430\n",
            "[Epoch 170] Loss: 0.3664\n",
            "[Epoch 170] Val Acc: 0.7480 | Test Acc: 0.7490\n",
            "[Epoch 180] Loss: 0.3689\n",
            "[Epoch 180] Val Acc: 0.7400 | Test Acc: 0.7430\n",
            "[Epoch 190] Loss: 0.3706\n",
            "[Epoch 190] Val Acc: 0.7440 | Test Acc: 0.7440\n",
            "[Epoch 200] Loss: 0.3620\n",
            "[Epoch 200] Val Acc: 0.7500 | Test Acc: 0.7470\n",
            "\n",
            "---------- GCN | Citeseer ----------\n",
            "[Epoch  10] Loss: 1.7369\n",
            "[Epoch  10] Val Acc: 0.4920 | Test Acc: 0.4940\n",
            "[Epoch  20] Loss: 1.6559\n",
            "[Epoch  20] Val Acc: 0.6220 | Test Acc: 0.6290\n",
            "[Epoch  30] Loss: 1.5436\n",
            "[Epoch  30] Val Acc: 0.6560 | Test Acc: 0.6650\n",
            "[Epoch  40] Loss: 1.4007\n",
            "[Epoch  40] Val Acc: 0.6840 | Test Acc: 0.6790\n",
            "[Epoch  50] Loss: 1.2630\n",
            "[Epoch  50] Val Acc: 0.6720 | Test Acc: 0.6890\n",
            "[Epoch  60] Loss: 1.1005\n",
            "[Epoch  60] Val Acc: 0.6820 | Test Acc: 0.6930\n",
            "[Epoch  70] Loss: 1.0051\n",
            "[Epoch  70] Val Acc: 0.6920 | Test Acc: 0.6950\n",
            "[Epoch  80] Loss: 0.9330\n",
            "[Epoch  80] Val Acc: 0.6780 | Test Acc: 0.6930\n",
            "[Epoch  90] Loss: 0.8272\n",
            "[Epoch  90] Val Acc: 0.6940 | Test Acc: 0.7070\n",
            "[Epoch 100] Loss: 0.7575\n",
            "[Epoch 100] Val Acc: 0.6960 | Test Acc: 0.7100\n",
            "[Epoch 110] Loss: 0.7019\n",
            "[Epoch 110] Val Acc: 0.7000 | Test Acc: 0.7090\n",
            "[Epoch 120] Loss: 0.6428\n",
            "[Epoch 120] Val Acc: 0.7080 | Test Acc: 0.7100\n",
            "[Epoch 130] Loss: 0.5991\n",
            "[Epoch 130] Val Acc: 0.7080 | Test Acc: 0.7120\n",
            "[Epoch 140] Loss: 0.6056\n",
            "[Epoch 140] Val Acc: 0.7200 | Test Acc: 0.7100\n",
            "[Epoch 150] Loss: 0.5624\n",
            "[Epoch 150] Val Acc: 0.7140 | Test Acc: 0.7130\n",
            "[Epoch 160] Loss: 0.5299\n",
            "[Epoch 160] Val Acc: 0.7120 | Test Acc: 0.7120\n",
            "[Epoch 170] Loss: 0.5068\n",
            "[Epoch 170] Val Acc: 0.7180 | Test Acc: 0.7120\n",
            "[Epoch 180] Loss: 0.5052\n",
            "[Epoch 180] Val Acc: 0.7160 | Test Acc: 0.7150\n",
            "[Epoch 190] Loss: 0.4203\n",
            "[Epoch 190] Val Acc: 0.7140 | Test Acc: 0.7160\n",
            "[Epoch 200] Loss: 0.4238\n",
            "[Epoch 200] Val Acc: 0.7080 | Test Acc: 0.7130\n",
            "\n",
            "---------- GCN | Citeseer_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 0.5598\n",
            "[Epoch  10] Val Acc: 0.3280 | Test Acc: 0.3280\n",
            "[Epoch  20] Loss: 0.2173\n",
            "[Epoch  20] Val Acc: 0.3420 | Test Acc: 0.3450\n",
            "[Epoch  30] Loss: 0.1021\n",
            "[Epoch  30] Val Acc: 0.3280 | Test Acc: 0.3530\n",
            "[Epoch  40] Loss: 0.0463\n",
            "[Epoch  40] Val Acc: 0.3260 | Test Acc: 0.3570\n",
            "[Epoch  50] Loss: 0.0407\n",
            "[Epoch  50] Val Acc: 0.3240 | Test Acc: 0.3450\n",
            "[Epoch  60] Loss: 0.0577\n",
            "[Epoch  60] Val Acc: 0.3360 | Test Acc: 0.3450\n",
            "[Epoch  70] Loss: 0.0420\n",
            "[Epoch  70] Val Acc: 0.3540 | Test Acc: 0.3510\n",
            "[Epoch  80] Loss: 0.0451\n",
            "[Epoch  80] Val Acc: 0.3320 | Test Acc: 0.3440\n",
            "[Epoch  90] Loss: 0.0376\n",
            "[Epoch  90] Val Acc: 0.3480 | Test Acc: 0.3480\n",
            "[Epoch 100] Loss: 0.0260\n",
            "[Epoch 100] Val Acc: 0.3360 | Test Acc: 0.3440\n",
            "[Epoch 110] Loss: 0.0528\n",
            "[Epoch 110] Val Acc: 0.3360 | Test Acc: 0.3430\n",
            "[Epoch 120] Loss: 0.0418\n",
            "[Epoch 120] Val Acc: 0.3300 | Test Acc: 0.3500\n",
            "[Epoch 130] Loss: 0.0475\n",
            "[Epoch 130] Val Acc: 0.3280 | Test Acc: 0.3430\n",
            "[Epoch 140] Loss: 0.0357\n",
            "[Epoch 140] Val Acc: 0.3260 | Test Acc: 0.3470\n",
            "[Epoch 150] Loss: 0.0440\n",
            "[Epoch 150] Val Acc: 0.3300 | Test Acc: 0.3360\n",
            "[Epoch 160] Loss: 0.0261\n",
            "[Epoch 160] Val Acc: 0.3160 | Test Acc: 0.3420\n",
            "[Epoch 170] Loss: 0.0366\n",
            "[Epoch 170] Val Acc: 0.3240 | Test Acc: 0.3380\n",
            "[Epoch 180] Loss: 0.0301\n",
            "[Epoch 180] Val Acc: 0.3260 | Test Acc: 0.3330\n",
            "[Epoch 190] Loss: 0.0247\n",
            "[Epoch 190] Val Acc: 0.3140 | Test Acc: 0.3250\n",
            "[Epoch 200] Loss: 0.0574\n",
            "[Epoch 200] Val Acc: 0.3240 | Test Acc: 0.3290\n",
            "\n",
            "---------- GCN | Citeseer_perturbation ----------\n",
            "[Epoch  10] Loss: 1.7260\n",
            "[Epoch  10] Val Acc: 0.5700 | Test Acc: 0.5530\n",
            "[Epoch  20] Loss: 1.6408\n",
            "[Epoch  20] Val Acc: 0.6000 | Test Acc: 0.5950\n",
            "[Epoch  30] Loss: 1.5290\n",
            "[Epoch  30] Val Acc: 0.6340 | Test Acc: 0.6310\n",
            "[Epoch  40] Loss: 1.4161\n",
            "[Epoch  40] Val Acc: 0.6440 | Test Acc: 0.6370\n",
            "[Epoch  50] Loss: 1.2603\n",
            "[Epoch  50] Val Acc: 0.6780 | Test Acc: 0.6650\n",
            "[Epoch  60] Loss: 1.1483\n",
            "[Epoch  60] Val Acc: 0.6800 | Test Acc: 0.6850\n",
            "[Epoch  70] Loss: 1.0480\n",
            "[Epoch  70] Val Acc: 0.6780 | Test Acc: 0.6690\n",
            "[Epoch  80] Loss: 0.9377\n",
            "[Epoch  80] Val Acc: 0.6820 | Test Acc: 0.6770\n",
            "[Epoch  90] Loss: 0.8519\n",
            "[Epoch  90] Val Acc: 0.6960 | Test Acc: 0.6780\n",
            "[Epoch 100] Loss: 0.7939\n",
            "[Epoch 100] Val Acc: 0.6920 | Test Acc: 0.6750\n",
            "[Epoch 110] Loss: 0.7406\n",
            "[Epoch 110] Val Acc: 0.7000 | Test Acc: 0.6820\n",
            "[Epoch 120] Loss: 0.7000\n",
            "[Epoch 120] Val Acc: 0.6900 | Test Acc: 0.6790\n",
            "[Epoch 130] Loss: 0.6290\n",
            "[Epoch 130] Val Acc: 0.6980 | Test Acc: 0.6850\n",
            "[Epoch 140] Loss: 0.6094\n",
            "[Epoch 140] Val Acc: 0.7120 | Test Acc: 0.6870\n",
            "[Epoch 150] Loss: 0.5667\n",
            "[Epoch 150] Val Acc: 0.7100 | Test Acc: 0.6850\n",
            "[Epoch 160] Loss: 0.5539\n",
            "[Epoch 160] Val Acc: 0.6920 | Test Acc: 0.6850\n",
            "[Epoch 170] Loss: 0.5739\n",
            "[Epoch 170] Val Acc: 0.7060 | Test Acc: 0.6790\n",
            "[Epoch 180] Loss: 0.5256\n",
            "[Epoch 180] Val Acc: 0.7020 | Test Acc: 0.6810\n",
            "[Epoch 190] Loss: 0.4654\n",
            "[Epoch 190] Val Acc: 0.6880 | Test Acc: 0.6820\n",
            "[Epoch 200] Loss: 0.4585\n",
            "[Epoch 200] Val Acc: 0.7000 | Test Acc: 0.6800\n",
            "\n",
            "---------- GCN | Citeseer_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.7488\n",
            "[Epoch  10] Val Acc: 0.2280 | Test Acc: 0.2710\n",
            "[Epoch  20] Loss: 1.6500\n",
            "[Epoch  20] Val Acc: 0.3520 | Test Acc: 0.3760\n",
            "[Epoch  30] Loss: 1.5433\n",
            "[Epoch  30] Val Acc: 0.4720 | Test Acc: 0.4860\n",
            "[Epoch  40] Loss: 1.4385\n",
            "[Epoch  40] Val Acc: 0.4900 | Test Acc: 0.5220\n",
            "[Epoch  50] Loss: 1.2970\n",
            "[Epoch  50] Val Acc: 0.4960 | Test Acc: 0.5450\n",
            "[Epoch  60] Loss: 1.1782\n",
            "[Epoch  60] Val Acc: 0.5840 | Test Acc: 0.6210\n",
            "[Epoch  70] Loss: 1.0476\n",
            "[Epoch  70] Val Acc: 0.6320 | Test Acc: 0.6540\n",
            "[Epoch  80] Loss: 0.9641\n",
            "[Epoch  80] Val Acc: 0.6420 | Test Acc: 0.6670\n",
            "[Epoch  90] Loss: 0.8898\n",
            "[Epoch  90] Val Acc: 0.6480 | Test Acc: 0.6730\n",
            "[Epoch 100] Loss: 0.8078\n",
            "[Epoch 100] Val Acc: 0.6560 | Test Acc: 0.6730\n",
            "[Epoch 110] Loss: 0.7891\n",
            "[Epoch 110] Val Acc: 0.6440 | Test Acc: 0.6710\n",
            "[Epoch 120] Loss: 0.7098\n",
            "[Epoch 120] Val Acc: 0.6420 | Test Acc: 0.6700\n",
            "[Epoch 130] Loss: 0.6644\n",
            "[Epoch 130] Val Acc: 0.6560 | Test Acc: 0.6740\n",
            "[Epoch 140] Loss: 0.5950\n",
            "[Epoch 140] Val Acc: 0.6600 | Test Acc: 0.6800\n",
            "[Epoch 150] Loss: 0.5821\n",
            "[Epoch 150] Val Acc: 0.6580 | Test Acc: 0.6780\n",
            "[Epoch 160] Loss: 0.6000\n",
            "[Epoch 160] Val Acc: 0.6520 | Test Acc: 0.6720\n",
            "[Epoch 170] Loss: 0.5916\n",
            "[Epoch 170] Val Acc: 0.6540 | Test Acc: 0.6680\n",
            "[Epoch 180] Loss: 0.5612\n",
            "[Epoch 180] Val Acc: 0.6540 | Test Acc: 0.6770\n",
            "[Epoch 190] Loss: 0.5509\n",
            "[Epoch 190] Val Acc: 0.6520 | Test Acc: 0.6700\n",
            "[Epoch 200] Loss: 0.5227\n",
            "[Epoch 200] Val Acc: 0.6560 | Test Acc: 0.6740\n",
            "\n",
            "---------- GCN | Pubmed ----------\n",
            "[Epoch  10] Loss: 1.0210\n",
            "[Epoch  10] Val Acc: 0.6860 | Test Acc: 0.6880\n",
            "[Epoch  20] Loss: 0.8972\n",
            "[Epoch  20] Val Acc: 0.7340 | Test Acc: 0.7340\n",
            "[Epoch  30] Loss: 0.7196\n",
            "[Epoch  30] Val Acc: 0.7460 | Test Acc: 0.7280\n",
            "[Epoch  40] Loss: 0.5748\n",
            "[Epoch  40] Val Acc: 0.7720 | Test Acc: 0.7610\n",
            "[Epoch  50] Loss: 0.4732\n",
            "[Epoch  50] Val Acc: 0.7720 | Test Acc: 0.7690\n",
            "[Epoch  60] Loss: 0.4080\n",
            "[Epoch  60] Val Acc: 0.7840 | Test Acc: 0.7800\n",
            "[Epoch  70] Loss: 0.3284\n",
            "[Epoch  70] Val Acc: 0.8000 | Test Acc: 0.7820\n",
            "[Epoch  80] Loss: 0.2739\n",
            "[Epoch  80] Val Acc: 0.7860 | Test Acc: 0.7820\n",
            "[Epoch  90] Loss: 0.2450\n",
            "[Epoch  90] Val Acc: 0.7900 | Test Acc: 0.7860\n",
            "[Epoch 100] Loss: 0.2225\n",
            "[Epoch 100] Val Acc: 0.7900 | Test Acc: 0.7860\n",
            "[Epoch 110] Loss: 0.2451\n",
            "[Epoch 110] Val Acc: 0.7920 | Test Acc: 0.7850\n",
            "[Epoch 120] Loss: 0.1977\n",
            "[Epoch 120] Val Acc: 0.7940 | Test Acc: 0.7870\n",
            "[Epoch 130] Loss: 0.1894\n",
            "[Epoch 130] Val Acc: 0.7960 | Test Acc: 0.7940\n",
            "[Epoch 140] Loss: 0.1897\n",
            "[Epoch 140] Val Acc: 0.7900 | Test Acc: 0.7930\n",
            "[Epoch 150] Loss: 0.1580\n",
            "[Epoch 150] Val Acc: 0.7880 | Test Acc: 0.7880\n",
            "[Epoch 160] Loss: 0.1860\n",
            "[Epoch 160] Val Acc: 0.7940 | Test Acc: 0.7870\n",
            "[Epoch 170] Loss: 0.1905\n",
            "[Epoch 170] Val Acc: 0.7980 | Test Acc: 0.7890\n",
            "[Epoch 180] Loss: 0.1418\n",
            "[Epoch 180] Val Acc: 0.7940 | Test Acc: 0.7890\n",
            "[Epoch 190] Loss: 0.1547\n",
            "[Epoch 190] Val Acc: 0.7960 | Test Acc: 0.7900\n",
            "[Epoch 200] Loss: 0.1588\n",
            "[Epoch 200] Val Acc: 0.7960 | Test Acc: 0.7910\n",
            "\n",
            "---------- GCN | Pubmed_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 0.8510\n",
            "[Epoch  10] Val Acc: 0.4480 | Test Acc: 0.4310\n",
            "[Epoch  20] Loss: 0.4483\n",
            "[Epoch  20] Val Acc: 0.4200 | Test Acc: 0.4220\n",
            "[Epoch  30] Loss: 0.2193\n",
            "[Epoch  30] Val Acc: 0.4220 | Test Acc: 0.4330\n",
            "[Epoch  40] Loss: 0.1275\n",
            "[Epoch  40] Val Acc: 0.4140 | Test Acc: 0.4220\n",
            "[Epoch  50] Loss: 0.0568\n",
            "[Epoch  50] Val Acc: 0.4180 | Test Acc: 0.4260\n",
            "[Epoch  60] Loss: 0.0491\n",
            "[Epoch  60] Val Acc: 0.4160 | Test Acc: 0.4280\n",
            "[Epoch  70] Loss: 0.0424\n",
            "[Epoch  70] Val Acc: 0.4220 | Test Acc: 0.4250\n",
            "[Epoch  80] Loss: 0.0342\n",
            "[Epoch  80] Val Acc: 0.4140 | Test Acc: 0.4220\n",
            "[Epoch  90] Loss: 0.0293\n",
            "[Epoch  90] Val Acc: 0.4080 | Test Acc: 0.4190\n",
            "[Epoch 100] Loss: 0.0380\n",
            "[Epoch 100] Val Acc: 0.4180 | Test Acc: 0.4130\n",
            "[Epoch 110] Loss: 0.0304\n",
            "[Epoch 110] Val Acc: 0.4100 | Test Acc: 0.4180\n",
            "[Epoch 120] Loss: 0.0275\n",
            "[Epoch 120] Val Acc: 0.4240 | Test Acc: 0.4160\n",
            "[Epoch 130] Loss: 0.0618\n",
            "[Epoch 130] Val Acc: 0.4120 | Test Acc: 0.4160\n",
            "[Epoch 140] Loss: 0.0295\n",
            "[Epoch 140] Val Acc: 0.4080 | Test Acc: 0.4040\n",
            "[Epoch 150] Loss: 0.0317\n",
            "[Epoch 150] Val Acc: 0.4040 | Test Acc: 0.4090\n",
            "[Epoch 160] Loss: 0.0412\n",
            "[Epoch 160] Val Acc: 0.3960 | Test Acc: 0.4130\n",
            "[Epoch 170] Loss: 0.0333\n",
            "[Epoch 170] Val Acc: 0.3960 | Test Acc: 0.4130\n",
            "[Epoch 180] Loss: 0.0331\n",
            "[Epoch 180] Val Acc: 0.4020 | Test Acc: 0.4220\n",
            "[Epoch 190] Loss: 0.0249\n",
            "[Epoch 190] Val Acc: 0.3980 | Test Acc: 0.4150\n",
            "[Epoch 200] Loss: 0.0274\n",
            "[Epoch 200] Val Acc: 0.4100 | Test Acc: 0.4160\n",
            "\n",
            "---------- GCN | Pubmed_perturbation ----------\n",
            "[Epoch  10] Loss: 1.0115\n",
            "[Epoch  10] Val Acc: 0.7020 | Test Acc: 0.6800\n",
            "[Epoch  20] Loss: 0.8811\n",
            "[Epoch  20] Val Acc: 0.6780 | Test Acc: 0.6540\n",
            "[Epoch  30] Loss: 0.7174\n",
            "[Epoch  30] Val Acc: 0.7240 | Test Acc: 0.6960\n",
            "[Epoch  40] Loss: 0.6651\n",
            "[Epoch  40] Val Acc: 0.7520 | Test Acc: 0.7310\n",
            "[Epoch  50] Loss: 0.4841\n",
            "[Epoch  50] Val Acc: 0.7680 | Test Acc: 0.7450\n",
            "[Epoch  60] Loss: 0.4558\n",
            "[Epoch  60] Val Acc: 0.7760 | Test Acc: 0.7510\n",
            "[Epoch  70] Loss: 0.3550\n",
            "[Epoch  70] Val Acc: 0.7900 | Test Acc: 0.7620\n",
            "[Epoch  80] Loss: 0.3372\n",
            "[Epoch  80] Val Acc: 0.7860 | Test Acc: 0.7690\n",
            "[Epoch  90] Loss: 0.3020\n",
            "[Epoch  90] Val Acc: 0.7980 | Test Acc: 0.7750\n",
            "[Epoch 100] Loss: 0.2497\n",
            "[Epoch 100] Val Acc: 0.8000 | Test Acc: 0.7780\n",
            "[Epoch 110] Loss: 0.2726\n",
            "[Epoch 110] Val Acc: 0.7960 | Test Acc: 0.7790\n",
            "[Epoch 120] Loss: 0.2479\n",
            "[Epoch 120] Val Acc: 0.7940 | Test Acc: 0.7730\n",
            "[Epoch 130] Loss: 0.2557\n",
            "[Epoch 130] Val Acc: 0.7980 | Test Acc: 0.7760\n",
            "[Epoch 140] Loss: 0.1914\n",
            "[Epoch 140] Val Acc: 0.7940 | Test Acc: 0.7770\n",
            "[Epoch 150] Loss: 0.1674\n",
            "[Epoch 150] Val Acc: 0.7940 | Test Acc: 0.7780\n",
            "[Epoch 160] Loss: 0.1757\n",
            "[Epoch 160] Val Acc: 0.7880 | Test Acc: 0.7750\n",
            "[Epoch 170] Loss: 0.1768\n",
            "[Epoch 170] Val Acc: 0.7900 | Test Acc: 0.7710\n",
            "[Epoch 180] Loss: 0.1951\n",
            "[Epoch 180] Val Acc: 0.7900 | Test Acc: 0.7780\n",
            "[Epoch 190] Loss: 0.2003\n",
            "[Epoch 190] Val Acc: 0.7880 | Test Acc: 0.7780\n",
            "[Epoch 200] Loss: 0.1547\n",
            "[Epoch 200] Val Acc: 0.7840 | Test Acc: 0.7780\n",
            "\n",
            "---------- GCN | Pubmed_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.0212\n",
            "[Epoch  10] Val Acc: 0.2640 | Test Acc: 0.2730\n",
            "[Epoch  20] Loss: 0.9169\n",
            "[Epoch  20] Val Acc: 0.5200 | Test Acc: 0.4980\n",
            "[Epoch  30] Loss: 0.8509\n",
            "[Epoch  30] Val Acc: 0.6500 | Test Acc: 0.6330\n",
            "[Epoch  40] Loss: 0.7283\n",
            "[Epoch  40] Val Acc: 0.6920 | Test Acc: 0.6940\n",
            "[Epoch  50] Loss: 0.6178\n",
            "[Epoch  50] Val Acc: 0.7040 | Test Acc: 0.7150\n",
            "[Epoch  60] Loss: 0.5492\n",
            "[Epoch  60] Val Acc: 0.7260 | Test Acc: 0.7230\n",
            "[Epoch  70] Loss: 0.4472\n",
            "[Epoch  70] Val Acc: 0.7060 | Test Acc: 0.7070\n",
            "[Epoch  80] Loss: 0.4141\n",
            "[Epoch  80] Val Acc: 0.7240 | Test Acc: 0.7140\n",
            "[Epoch  90] Loss: 0.3671\n",
            "[Epoch  90] Val Acc: 0.7340 | Test Acc: 0.7170\n",
            "[Epoch 100] Loss: 0.3190\n",
            "[Epoch 100] Val Acc: 0.7300 | Test Acc: 0.7200\n",
            "[Epoch 110] Loss: 0.3232\n",
            "[Epoch 110] Val Acc: 0.7180 | Test Acc: 0.6990\n",
            "[Epoch 120] Loss: 0.3010\n",
            "[Epoch 120] Val Acc: 0.7220 | Test Acc: 0.7010\n",
            "[Epoch 130] Loss: 0.2513\n",
            "[Epoch 130] Val Acc: 0.7120 | Test Acc: 0.6960\n",
            "[Epoch 140] Loss: 0.2680\n",
            "[Epoch 140] Val Acc: 0.7080 | Test Acc: 0.7010\n",
            "[Epoch 150] Loss: 0.2221\n",
            "[Epoch 150] Val Acc: 0.6940 | Test Acc: 0.7000\n",
            "[Epoch 160] Loss: 0.2393\n",
            "[Epoch 160] Val Acc: 0.6980 | Test Acc: 0.6960\n",
            "[Epoch 170] Loss: 0.2297\n",
            "[Epoch 170] Val Acc: 0.6960 | Test Acc: 0.6950\n",
            "[Epoch 180] Loss: 0.2059\n",
            "[Epoch 180] Val Acc: 0.6940 | Test Acc: 0.6930\n",
            "[Epoch 190] Loss: 0.1867\n",
            "[Epoch 190] Val Acc: 0.6860 | Test Acc: 0.6940\n",
            "[Epoch 200] Loss: 0.1819\n",
            "[Epoch 200] Val Acc: 0.6960 | Test Acc: 0.7020\n",
            "\n",
            "---------- HyperGCN | Cora ----------\n",
            "[Epoch  10] Loss: 1.8767\n",
            "[Epoch  10] Val Acc: 0.6380 | Test Acc: 0.6350\n",
            "[Epoch  20] Loss: 1.7619\n",
            "[Epoch  20] Val Acc: 0.7520 | Test Acc: 0.7370\n",
            "[Epoch  30] Loss: 1.5943\n",
            "[Epoch  30] Val Acc: 0.7620 | Test Acc: 0.7660\n",
            "[Epoch  40] Loss: 1.4127\n",
            "[Epoch  40] Val Acc: 0.8040 | Test Acc: 0.7870\n",
            "[Epoch  50] Loss: 1.2039\n",
            "[Epoch  50] Val Acc: 0.8000 | Test Acc: 0.7950\n",
            "[Epoch  60] Loss: 0.9726\n",
            "[Epoch  60] Val Acc: 0.7860 | Test Acc: 0.7930\n",
            "[Epoch  70] Loss: 0.8399\n",
            "[Epoch  70] Val Acc: 0.8060 | Test Acc: 0.8060\n",
            "[Epoch  80] Loss: 0.7158\n",
            "[Epoch  80] Val Acc: 0.7960 | Test Acc: 0.8080\n",
            "[Epoch  90] Loss: 0.6453\n",
            "[Epoch  90] Val Acc: 0.7900 | Test Acc: 0.8080\n",
            "[Epoch 100] Loss: 0.5526\n",
            "[Epoch 100] Val Acc: 0.8000 | Test Acc: 0.8110\n",
            "[Epoch 110] Loss: 0.4937\n",
            "[Epoch 110] Val Acc: 0.8000 | Test Acc: 0.8080\n",
            "[Epoch 120] Loss: 0.5078\n",
            "[Epoch 120] Val Acc: 0.8040 | Test Acc: 0.8110\n",
            "[Epoch 130] Loss: 0.4346\n",
            "[Epoch 130] Val Acc: 0.8080 | Test Acc: 0.8130\n",
            "[Epoch 140] Loss: 0.4250\n",
            "[Epoch 140] Val Acc: 0.8040 | Test Acc: 0.8120\n",
            "[Epoch 150] Loss: 0.4109\n",
            "[Epoch 150] Val Acc: 0.7980 | Test Acc: 0.8110\n",
            "[Epoch 160] Loss: 0.3789\n",
            "[Epoch 160] Val Acc: 0.7980 | Test Acc: 0.8100\n",
            "[Epoch 170] Loss: 0.3854\n",
            "[Epoch 170] Val Acc: 0.8040 | Test Acc: 0.8140\n",
            "[Epoch 180] Loss: 0.3555\n",
            "[Epoch 180] Val Acc: 0.8040 | Test Acc: 0.8120\n",
            "[Epoch 190] Loss: 0.3442\n",
            "[Epoch 190] Val Acc: 0.8040 | Test Acc: 0.8060\n",
            "[Epoch 200] Loss: 0.3257\n",
            "[Epoch 200] Val Acc: 0.8020 | Test Acc: 0.8110\n",
            "\n",
            "---------- HyperGCN | Cora_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 1.1868\n",
            "[Epoch  10] Val Acc: 0.6340 | Test Acc: 0.6400\n",
            "[Epoch  20] Loss: 0.4618\n",
            "[Epoch  20] Val Acc: 0.6480 | Test Acc: 0.6510\n",
            "[Epoch  30] Loss: 0.1877\n",
            "[Epoch  30] Val Acc: 0.6580 | Test Acc: 0.6610\n",
            "[Epoch  40] Loss: 0.0875\n",
            "[Epoch  40] Val Acc: 0.6600 | Test Acc: 0.6650\n",
            "[Epoch  50] Loss: 0.0780\n",
            "[Epoch  50] Val Acc: 0.6640 | Test Acc: 0.6680\n",
            "[Epoch  60] Loss: 0.0528\n",
            "[Epoch  60] Val Acc: 0.6780 | Test Acc: 0.6750\n",
            "[Epoch  70] Loss: 0.0428\n",
            "[Epoch  70] Val Acc: 0.6820 | Test Acc: 0.6840\n",
            "[Epoch  80] Loss: 0.0667\n",
            "[Epoch  80] Val Acc: 0.6800 | Test Acc: 0.6810\n",
            "[Epoch  90] Loss: 0.0639\n",
            "[Epoch  90] Val Acc: 0.6820 | Test Acc: 0.6890\n",
            "[Epoch 100] Loss: 0.0665\n",
            "[Epoch 100] Val Acc: 0.6860 | Test Acc: 0.6940\n",
            "[Epoch 110] Loss: 0.0485\n",
            "[Epoch 110] Val Acc: 0.6760 | Test Acc: 0.6830\n",
            "[Epoch 120] Loss: 0.0565\n",
            "[Epoch 120] Val Acc: 0.6760 | Test Acc: 0.6810\n",
            "[Epoch 130] Loss: 0.0465\n",
            "[Epoch 130] Val Acc: 0.6840 | Test Acc: 0.6930\n",
            "[Epoch 140] Loss: 0.0572\n",
            "[Epoch 140] Val Acc: 0.6780 | Test Acc: 0.6830\n",
            "[Epoch 150] Loss: 0.0486\n",
            "[Epoch 150] Val Acc: 0.6740 | Test Acc: 0.6770\n",
            "[Epoch 160] Loss: 0.0473\n",
            "[Epoch 160] Val Acc: 0.6740 | Test Acc: 0.6810\n",
            "[Epoch 170] Loss: 0.0315\n",
            "[Epoch 170] Val Acc: 0.6700 | Test Acc: 0.6830\n",
            "[Epoch 180] Loss: 0.0389\n",
            "[Epoch 180] Val Acc: 0.6760 | Test Acc: 0.6820\n",
            "[Epoch 190] Loss: 0.0312\n",
            "[Epoch 190] Val Acc: 0.6720 | Test Acc: 0.6800\n",
            "[Epoch 200] Loss: 0.0349\n",
            "[Epoch 200] Val Acc: 0.6740 | Test Acc: 0.6810\n",
            "\n",
            "---------- HyperGCN | Cora_perturbation ----------\n",
            "[Epoch  10] Loss: 1.8879\n",
            "[Epoch  10] Val Acc: 0.6440 | Test Acc: 0.6270\n",
            "[Epoch  20] Loss: 1.7782\n",
            "[Epoch  20] Val Acc: 0.6860 | Test Acc: 0.6690\n",
            "[Epoch  30] Loss: 1.6448\n",
            "[Epoch  30] Val Acc: 0.7200 | Test Acc: 0.7050\n",
            "[Epoch  40] Loss: 1.4494\n",
            "[Epoch  40] Val Acc: 0.7300 | Test Acc: 0.7200\n",
            "[Epoch  50] Loss: 1.2438\n",
            "[Epoch  50] Val Acc: 0.7380 | Test Acc: 0.7290\n",
            "[Epoch  60] Loss: 1.0561\n",
            "[Epoch  60] Val Acc: 0.7580 | Test Acc: 0.7470\n",
            "[Epoch  70] Loss: 0.8903\n",
            "[Epoch  70] Val Acc: 0.7720 | Test Acc: 0.7640\n",
            "[Epoch  80] Loss: 0.7898\n",
            "[Epoch  80] Val Acc: 0.7700 | Test Acc: 0.7770\n",
            "[Epoch  90] Loss: 0.6921\n",
            "[Epoch  90] Val Acc: 0.7780 | Test Acc: 0.7880\n",
            "[Epoch 100] Loss: 0.6383\n",
            "[Epoch 100] Val Acc: 0.7760 | Test Acc: 0.7920\n",
            "[Epoch 110] Loss: 0.5527\n",
            "[Epoch 110] Val Acc: 0.7900 | Test Acc: 0.8040\n",
            "[Epoch 120] Loss: 0.5050\n",
            "[Epoch 120] Val Acc: 0.7940 | Test Acc: 0.8010\n",
            "[Epoch 130] Loss: 0.5015\n",
            "[Epoch 130] Val Acc: 0.7860 | Test Acc: 0.7970\n",
            "[Epoch 140] Loss: 0.4490\n",
            "[Epoch 140] Val Acc: 0.7820 | Test Acc: 0.7950\n",
            "[Epoch 150] Loss: 0.4323\n",
            "[Epoch 150] Val Acc: 0.7820 | Test Acc: 0.8000\n",
            "[Epoch 160] Loss: 0.4342\n",
            "[Epoch 160] Val Acc: 0.7920 | Test Acc: 0.7910\n",
            "[Epoch 170] Loss: 0.3872\n",
            "[Epoch 170] Val Acc: 0.7840 | Test Acc: 0.8030\n",
            "[Epoch 180] Loss: 0.4055\n",
            "[Epoch 180] Val Acc: 0.7980 | Test Acc: 0.8080\n",
            "[Epoch 190] Loss: 0.3934\n",
            "[Epoch 190] Val Acc: 0.7920 | Test Acc: 0.8070\n",
            "[Epoch 200] Loss: 0.3736\n",
            "[Epoch 200] Val Acc: 0.7800 | Test Acc: 0.7990\n",
            "\n",
            "---------- HyperGCN | Cora_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.8851\n",
            "[Epoch  10] Val Acc: 0.1400 | Test Acc: 0.1400\n",
            "[Epoch  20] Loss: 1.7795\n",
            "[Epoch  20] Val Acc: 0.3000 | Test Acc: 0.3190\n",
            "[Epoch  30] Loss: 1.6284\n",
            "[Epoch  30] Val Acc: 0.4660 | Test Acc: 0.4590\n",
            "[Epoch  40] Loss: 1.4427\n",
            "[Epoch  40] Val Acc: 0.6440 | Test Acc: 0.6160\n",
            "[Epoch  50] Loss: 1.2557\n",
            "[Epoch  50] Val Acc: 0.6920 | Test Acc: 0.6630\n",
            "[Epoch  60] Loss: 1.0753\n",
            "[Epoch  60] Val Acc: 0.7280 | Test Acc: 0.7120\n",
            "[Epoch  70] Loss: 0.9369\n",
            "[Epoch  70] Val Acc: 0.7440 | Test Acc: 0.7250\n",
            "[Epoch  80] Loss: 0.8061\n",
            "[Epoch  80] Val Acc: 0.7520 | Test Acc: 0.7350\n",
            "[Epoch  90] Loss: 0.7349\n",
            "[Epoch  90] Val Acc: 0.7560 | Test Acc: 0.7520\n",
            "[Epoch 100] Loss: 0.6492\n",
            "[Epoch 100] Val Acc: 0.7580 | Test Acc: 0.7510\n",
            "[Epoch 110] Loss: 0.6095\n",
            "[Epoch 110] Val Acc: 0.7640 | Test Acc: 0.7600\n",
            "[Epoch 120] Loss: 0.5580\n",
            "[Epoch 120] Val Acc: 0.7620 | Test Acc: 0.7640\n",
            "[Epoch 130] Loss: 0.5349\n",
            "[Epoch 130] Val Acc: 0.7640 | Test Acc: 0.7490\n",
            "[Epoch 140] Loss: 0.5355\n",
            "[Epoch 140] Val Acc: 0.7580 | Test Acc: 0.7470\n",
            "[Epoch 150] Loss: 0.4958\n",
            "[Epoch 150] Val Acc: 0.7580 | Test Acc: 0.7590\n",
            "[Epoch 160] Loss: 0.4513\n",
            "[Epoch 160] Val Acc: 0.7720 | Test Acc: 0.7600\n",
            "[Epoch 170] Loss: 0.4369\n",
            "[Epoch 170] Val Acc: 0.7680 | Test Acc: 0.7620\n",
            "[Epoch 180] Loss: 0.4425\n",
            "[Epoch 180] Val Acc: 0.7600 | Test Acc: 0.7630\n",
            "[Epoch 190] Loss: 0.4420\n",
            "[Epoch 190] Val Acc: 0.7540 | Test Acc: 0.7620\n",
            "[Epoch 200] Loss: 0.4135\n",
            "[Epoch 200] Val Acc: 0.7620 | Test Acc: 0.7600\n",
            "\n",
            "---------- HyperGCN | Citeseer ----------\n",
            "[Epoch  10] Loss: 1.7422\n",
            "[Epoch  10] Val Acc: 0.6340 | Test Acc: 0.6340\n",
            "[Epoch  20] Loss: 1.6501\n",
            "[Epoch  20] Val Acc: 0.6720 | Test Acc: 0.6900\n",
            "[Epoch  30] Loss: 1.5330\n",
            "[Epoch  30] Val Acc: 0.6800 | Test Acc: 0.6970\n",
            "[Epoch  40] Loss: 1.4079\n",
            "[Epoch  40] Val Acc: 0.6860 | Test Acc: 0.7040\n",
            "[Epoch  50] Loss: 1.2687\n",
            "[Epoch  50] Val Acc: 0.6960 | Test Acc: 0.7030\n",
            "[Epoch  60] Loss: 1.0956\n",
            "[Epoch  60] Val Acc: 0.7040 | Test Acc: 0.7090\n",
            "[Epoch  70] Loss: 0.9769\n",
            "[Epoch  70] Val Acc: 0.7040 | Test Acc: 0.7050\n",
            "[Epoch  80] Loss: 0.8749\n",
            "[Epoch  80] Val Acc: 0.7080 | Test Acc: 0.7090\n",
            "[Epoch  90] Loss: 0.7403\n",
            "[Epoch  90] Val Acc: 0.7020 | Test Acc: 0.6960\n",
            "[Epoch 100] Loss: 0.6984\n",
            "[Epoch 100] Val Acc: 0.7080 | Test Acc: 0.7020\n",
            "[Epoch 110] Loss: 0.6255\n",
            "[Epoch 110] Val Acc: 0.7080 | Test Acc: 0.7050\n",
            "[Epoch 120] Loss: 0.5998\n",
            "[Epoch 120] Val Acc: 0.7080 | Test Acc: 0.6990\n",
            "[Epoch 130] Loss: 0.5792\n",
            "[Epoch 130] Val Acc: 0.7120 | Test Acc: 0.7030\n",
            "[Epoch 140] Loss: 0.5399\n",
            "[Epoch 140] Val Acc: 0.7120 | Test Acc: 0.6990\n",
            "[Epoch 150] Loss: 0.5387\n",
            "[Epoch 150] Val Acc: 0.7120 | Test Acc: 0.7010\n",
            "[Epoch 160] Loss: 0.5015\n",
            "[Epoch 160] Val Acc: 0.7120 | Test Acc: 0.7030\n",
            "[Epoch 170] Loss: 0.4811\n",
            "[Epoch 170] Val Acc: 0.7100 | Test Acc: 0.7020\n",
            "[Epoch 180] Loss: 0.4780\n",
            "[Epoch 180] Val Acc: 0.7100 | Test Acc: 0.7010\n",
            "[Epoch 190] Loss: 0.4438\n",
            "[Epoch 190] Val Acc: 0.7000 | Test Acc: 0.6970\n",
            "[Epoch 200] Loss: 0.4386\n",
            "[Epoch 200] Val Acc: 0.7040 | Test Acc: 0.7020\n",
            "\n",
            "---------- HyperGCN | Citeseer_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 0.6561\n",
            "[Epoch  10] Val Acc: 0.3920 | Test Acc: 0.4000\n",
            "[Epoch  20] Loss: 0.2137\n",
            "[Epoch  20] Val Acc: 0.4340 | Test Acc: 0.4330\n",
            "[Epoch  30] Loss: 0.1007\n",
            "[Epoch  30] Val Acc: 0.4320 | Test Acc: 0.4360\n",
            "[Epoch  40] Loss: 0.0752\n",
            "[Epoch  40] Val Acc: 0.4300 | Test Acc: 0.4340\n",
            "[Epoch  50] Loss: 0.0851\n",
            "[Epoch  50] Val Acc: 0.4160 | Test Acc: 0.4390\n",
            "[Epoch  60] Loss: 0.0542\n",
            "[Epoch  60] Val Acc: 0.4120 | Test Acc: 0.4340\n",
            "[Epoch  70] Loss: 0.0989\n",
            "[Epoch  70] Val Acc: 0.4100 | Test Acc: 0.4250\n",
            "[Epoch  80] Loss: 0.0907\n",
            "[Epoch  80] Val Acc: 0.4080 | Test Acc: 0.4300\n",
            "[Epoch  90] Loss: 0.0495\n",
            "[Epoch  90] Val Acc: 0.4060 | Test Acc: 0.4280\n",
            "[Epoch 100] Loss: 0.0562\n",
            "[Epoch 100] Val Acc: 0.4040 | Test Acc: 0.4270\n",
            "[Epoch 110] Loss: 0.0852\n",
            "[Epoch 110] Val Acc: 0.4040 | Test Acc: 0.4230\n",
            "[Epoch 120] Loss: 0.0445\n",
            "[Epoch 120] Val Acc: 0.4100 | Test Acc: 0.4190\n",
            "[Epoch 130] Loss: 0.0677\n",
            "[Epoch 130] Val Acc: 0.4080 | Test Acc: 0.4210\n",
            "[Epoch 140] Loss: 0.0442\n",
            "[Epoch 140] Val Acc: 0.4080 | Test Acc: 0.4170\n",
            "[Epoch 150] Loss: 0.0338\n",
            "[Epoch 150] Val Acc: 0.4080 | Test Acc: 0.4180\n",
            "[Epoch 160] Loss: 0.0647\n",
            "[Epoch 160] Val Acc: 0.4040 | Test Acc: 0.4140\n",
            "[Epoch 170] Loss: 0.0502\n",
            "[Epoch 170] Val Acc: 0.3960 | Test Acc: 0.4180\n",
            "[Epoch 180] Loss: 0.0564\n",
            "[Epoch 180] Val Acc: 0.4060 | Test Acc: 0.4210\n",
            "[Epoch 190] Loss: 0.0597\n",
            "[Epoch 190] Val Acc: 0.4060 | Test Acc: 0.4220\n",
            "[Epoch 200] Loss: 0.0922\n",
            "[Epoch 200] Val Acc: 0.4140 | Test Acc: 0.4310\n",
            "\n",
            "---------- HyperGCN | Citeseer_perturbation ----------\n",
            "[Epoch  10] Loss: 1.7419\n",
            "[Epoch  10] Val Acc: 0.5660 | Test Acc: 0.5330\n",
            "[Epoch  20] Loss: 1.6636\n",
            "[Epoch  20] Val Acc: 0.6760 | Test Acc: 0.6320\n",
            "[Epoch  30] Loss: 1.5487\n",
            "[Epoch  30] Val Acc: 0.6820 | Test Acc: 0.6360\n",
            "[Epoch  40] Loss: 1.3995\n",
            "[Epoch  40] Val Acc: 0.6700 | Test Acc: 0.6500\n",
            "[Epoch  50] Loss: 1.2813\n",
            "[Epoch  50] Val Acc: 0.6980 | Test Acc: 0.6830\n",
            "[Epoch  60] Loss: 1.1264\n",
            "[Epoch  60] Val Acc: 0.7000 | Test Acc: 0.6820\n",
            "[Epoch  70] Loss: 0.9757\n",
            "[Epoch  70] Val Acc: 0.6840 | Test Acc: 0.6740\n",
            "[Epoch  80] Loss: 0.9390\n",
            "[Epoch  80] Val Acc: 0.6860 | Test Acc: 0.6770\n",
            "[Epoch  90] Loss: 0.8655\n",
            "[Epoch  90] Val Acc: 0.6900 | Test Acc: 0.6840\n",
            "[Epoch 100] Loss: 0.7855\n",
            "[Epoch 100] Val Acc: 0.6860 | Test Acc: 0.6900\n",
            "[Epoch 110] Loss: 0.7399\n",
            "[Epoch 110] Val Acc: 0.6760 | Test Acc: 0.6830\n",
            "[Epoch 120] Loss: 0.7381\n",
            "[Epoch 120] Val Acc: 0.6880 | Test Acc: 0.6880\n",
            "[Epoch 130] Loss: 0.6416\n",
            "[Epoch 130] Val Acc: 0.7000 | Test Acc: 0.6870\n",
            "[Epoch 140] Loss: 0.6450\n",
            "[Epoch 140] Val Acc: 0.6960 | Test Acc: 0.6830\n",
            "[Epoch 150] Loss: 0.5610\n",
            "[Epoch 150] Val Acc: 0.6800 | Test Acc: 0.6850\n",
            "[Epoch 160] Loss: 0.5607\n",
            "[Epoch 160] Val Acc: 0.6820 | Test Acc: 0.6840\n",
            "[Epoch 170] Loss: 0.5524\n",
            "[Epoch 170] Val Acc: 0.6860 | Test Acc: 0.6810\n",
            "[Epoch 180] Loss: 0.4966\n",
            "[Epoch 180] Val Acc: 0.6880 | Test Acc: 0.6850\n",
            "[Epoch 190] Loss: 0.5097\n",
            "[Epoch 190] Val Acc: 0.6920 | Test Acc: 0.6830\n",
            "[Epoch 200] Loss: 0.5106\n",
            "[Epoch 200] Val Acc: 0.6880 | Test Acc: 0.6810\n",
            "\n",
            "---------- HyperGCN | Citeseer_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.7278\n",
            "[Epoch  10] Val Acc: 0.2440 | Test Acc: 0.2610\n",
            "[Epoch  20] Loss: 1.6239\n",
            "[Epoch  20] Val Acc: 0.3740 | Test Acc: 0.4070\n",
            "[Epoch  30] Loss: 1.4988\n",
            "[Epoch  30] Val Acc: 0.5040 | Test Acc: 0.5320\n",
            "[Epoch  40] Loss: 1.3824\n",
            "[Epoch  40] Val Acc: 0.5300 | Test Acc: 0.5520\n",
            "[Epoch  50] Loss: 1.2547\n",
            "[Epoch  50] Val Acc: 0.5940 | Test Acc: 0.6200\n",
            "[Epoch  60] Loss: 1.1212\n",
            "[Epoch  60] Val Acc: 0.6260 | Test Acc: 0.6480\n",
            "[Epoch  70] Loss: 1.0257\n",
            "[Epoch  70] Val Acc: 0.6440 | Test Acc: 0.6570\n",
            "[Epoch  80] Loss: 0.9204\n",
            "[Epoch  80] Val Acc: 0.6340 | Test Acc: 0.6580\n",
            "[Epoch  90] Loss: 0.8863\n",
            "[Epoch  90] Val Acc: 0.6540 | Test Acc: 0.6610\n",
            "[Epoch 100] Loss: 0.8112\n",
            "[Epoch 100] Val Acc: 0.6600 | Test Acc: 0.6620\n",
            "[Epoch 110] Loss: 0.7240\n",
            "[Epoch 110] Val Acc: 0.6620 | Test Acc: 0.6620\n",
            "[Epoch 120] Loss: 0.7401\n",
            "[Epoch 120] Val Acc: 0.6560 | Test Acc: 0.6670\n",
            "[Epoch 130] Loss: 0.7230\n",
            "[Epoch 130] Val Acc: 0.6560 | Test Acc: 0.6660\n",
            "[Epoch 140] Loss: 0.6631\n",
            "[Epoch 140] Val Acc: 0.6400 | Test Acc: 0.6630\n",
            "[Epoch 150] Loss: 0.5891\n",
            "[Epoch 150] Val Acc: 0.6400 | Test Acc: 0.6650\n",
            "[Epoch 160] Loss: 0.6176\n",
            "[Epoch 160] Val Acc: 0.6400 | Test Acc: 0.6610\n",
            "[Epoch 170] Loss: 0.5446\n",
            "[Epoch 170] Val Acc: 0.6460 | Test Acc: 0.6650\n",
            "[Epoch 180] Loss: 0.5607\n",
            "[Epoch 180] Val Acc: 0.6380 | Test Acc: 0.6620\n",
            "[Epoch 190] Loss: 0.5741\n",
            "[Epoch 190] Val Acc: 0.6480 | Test Acc: 0.6680\n",
            "[Epoch 200] Loss: 0.5434\n",
            "[Epoch 200] Val Acc: 0.6420 | Test Acc: 0.6620\n",
            "\n",
            "---------- HyperGCN | Pubmed ----------\n",
            "[Epoch  10] Loss: 1.0052\n",
            "[Epoch  10] Val Acc: 0.7140 | Test Acc: 0.6840\n",
            "[Epoch  20] Loss: 0.8549\n",
            "[Epoch  20] Val Acc: 0.7200 | Test Acc: 0.6790\n",
            "[Epoch  30] Loss: 0.6711\n",
            "[Epoch  30] Val Acc: 0.7300 | Test Acc: 0.6960\n",
            "[Epoch  40] Loss: 0.5558\n",
            "[Epoch  40] Val Acc: 0.7480 | Test Acc: 0.7170\n",
            "[Epoch  50] Loss: 0.4537\n",
            "[Epoch  50] Val Acc: 0.7720 | Test Acc: 0.7330\n",
            "[Epoch  60] Loss: 0.3730\n",
            "[Epoch  60] Val Acc: 0.7900 | Test Acc: 0.7610\n",
            "[Epoch  70] Loss: 0.3236\n",
            "[Epoch  70] Val Acc: 0.7940 | Test Acc: 0.7740\n",
            "[Epoch  80] Loss: 0.2932\n",
            "[Epoch  80] Val Acc: 0.7960 | Test Acc: 0.7760\n",
            "[Epoch  90] Loss: 0.2718\n",
            "[Epoch  90] Val Acc: 0.7960 | Test Acc: 0.7770\n",
            "[Epoch 100] Loss: 0.2549\n",
            "[Epoch 100] Val Acc: 0.7960 | Test Acc: 0.7750\n",
            "[Epoch 110] Loss: 0.2187\n",
            "[Epoch 110] Val Acc: 0.8000 | Test Acc: 0.7720\n",
            "[Epoch 120] Loss: 0.2183\n",
            "[Epoch 120] Val Acc: 0.7980 | Test Acc: 0.7740\n",
            "[Epoch 130] Loss: 0.1849\n",
            "[Epoch 130] Val Acc: 0.7960 | Test Acc: 0.7760\n",
            "[Epoch 140] Loss: 0.1858\n",
            "[Epoch 140] Val Acc: 0.8000 | Test Acc: 0.7780\n",
            "[Epoch 150] Loss: 0.1664\n",
            "[Epoch 150] Val Acc: 0.7980 | Test Acc: 0.7820\n",
            "[Epoch 160] Loss: 0.1758\n",
            "[Epoch 160] Val Acc: 0.7940 | Test Acc: 0.7810\n",
            "[Epoch 170] Loss: 0.1683\n",
            "[Epoch 170] Val Acc: 0.7900 | Test Acc: 0.7860\n",
            "[Epoch 180] Loss: 0.1559\n",
            "[Epoch 180] Val Acc: 0.7940 | Test Acc: 0.7890\n",
            "[Epoch 190] Loss: 0.1536\n",
            "[Epoch 190] Val Acc: 0.7880 | Test Acc: 0.7900\n",
            "[Epoch 200] Loss: 0.1561\n",
            "[Epoch 200] Val Acc: 0.7920 | Test Acc: 0.7860\n",
            "\n",
            "---------- HyperGCN | Pubmed_gaussiannoise ----------\n",
            "[Epoch  10] Loss: 0.7966\n",
            "[Epoch  10] Val Acc: 0.5220 | Test Acc: 0.5240\n",
            "[Epoch  20] Loss: 0.4074\n",
            "[Epoch  20] Val Acc: 0.5220 | Test Acc: 0.5470\n",
            "[Epoch  30] Loss: 0.2164\n",
            "[Epoch  30] Val Acc: 0.5380 | Test Acc: 0.5590\n",
            "[Epoch  40] Loss: 0.1065\n",
            "[Epoch  40] Val Acc: 0.5460 | Test Acc: 0.5710\n",
            "[Epoch  50] Loss: 0.0761\n",
            "[Epoch  50] Val Acc: 0.5560 | Test Acc: 0.5740\n",
            "[Epoch  60] Loss: 0.0449\n",
            "[Epoch  60] Val Acc: 0.5620 | Test Acc: 0.5710\n",
            "[Epoch  70] Loss: 0.0414\n",
            "[Epoch  70] Val Acc: 0.5620 | Test Acc: 0.5590\n",
            "[Epoch  80] Loss: 0.0426\n",
            "[Epoch  80] Val Acc: 0.5640 | Test Acc: 0.5620\n",
            "[Epoch  90] Loss: 0.0463\n",
            "[Epoch  90] Val Acc: 0.5660 | Test Acc: 0.5570\n",
            "[Epoch 100] Loss: 0.0392\n",
            "[Epoch 100] Val Acc: 0.5600 | Test Acc: 0.5580\n",
            "[Epoch 110] Loss: 0.0424\n",
            "[Epoch 110] Val Acc: 0.5660 | Test Acc: 0.5640\n",
            "[Epoch 120] Loss: 0.0381\n",
            "[Epoch 120] Val Acc: 0.5600 | Test Acc: 0.5650\n",
            "[Epoch 130] Loss: 0.0349\n",
            "[Epoch 130] Val Acc: 0.5560 | Test Acc: 0.5630\n",
            "[Epoch 140] Loss: 0.0316\n",
            "[Epoch 140] Val Acc: 0.5460 | Test Acc: 0.5610\n",
            "[Epoch 150] Loss: 0.0281\n",
            "[Epoch 150] Val Acc: 0.5640 | Test Acc: 0.5660\n",
            "[Epoch 160] Loss: 0.0403\n",
            "[Epoch 160] Val Acc: 0.5560 | Test Acc: 0.5600\n",
            "[Epoch 170] Loss: 0.0316\n",
            "[Epoch 170] Val Acc: 0.5660 | Test Acc: 0.5670\n",
            "[Epoch 180] Loss: 0.0320\n",
            "[Epoch 180] Val Acc: 0.5580 | Test Acc: 0.5670\n",
            "[Epoch 190] Loss: 0.0301\n",
            "[Epoch 190] Val Acc: 0.5520 | Test Acc: 0.5650\n",
            "[Epoch 200] Loss: 0.0229\n",
            "[Epoch 200] Val Acc: 0.5600 | Test Acc: 0.5630\n",
            "\n",
            "---------- HyperGCN | Pubmed_perturbation ----------\n",
            "[Epoch  10] Loss: 1.0386\n",
            "[Epoch  10] Val Acc: 0.6860 | Test Acc: 0.6750\n",
            "[Epoch  20] Loss: 0.9209\n",
            "[Epoch  20] Val Acc: 0.6980 | Test Acc: 0.6850\n",
            "[Epoch  30] Loss: 0.8030\n",
            "[Epoch  30] Val Acc: 0.7100 | Test Acc: 0.6910\n",
            "[Epoch  40] Loss: 0.6403\n",
            "[Epoch  40] Val Acc: 0.7240 | Test Acc: 0.7060\n",
            "[Epoch  50] Loss: 0.5562\n",
            "[Epoch  50] Val Acc: 0.7520 | Test Acc: 0.7210\n",
            "[Epoch  60] Loss: 0.4541\n",
            "[Epoch  60] Val Acc: 0.7720 | Test Acc: 0.7380\n",
            "[Epoch  70] Loss: 0.4074\n",
            "[Epoch  70] Val Acc: 0.7860 | Test Acc: 0.7560\n",
            "[Epoch  80] Loss: 0.3486\n",
            "[Epoch  80] Val Acc: 0.7920 | Test Acc: 0.7670\n",
            "[Epoch  90] Loss: 0.3435\n",
            "[Epoch  90] Val Acc: 0.8060 | Test Acc: 0.7710\n",
            "[Epoch 100] Loss: 0.2602\n",
            "[Epoch 100] Val Acc: 0.8020 | Test Acc: 0.7720\n",
            "[Epoch 110] Loss: 0.2509\n",
            "[Epoch 110] Val Acc: 0.7980 | Test Acc: 0.7750\n",
            "[Epoch 120] Loss: 0.2535\n",
            "[Epoch 120] Val Acc: 0.7940 | Test Acc: 0.7680\n",
            "[Epoch 130] Loss: 0.2490\n",
            "[Epoch 130] Val Acc: 0.8000 | Test Acc: 0.7700\n",
            "[Epoch 140] Loss: 0.2222\n",
            "[Epoch 140] Val Acc: 0.8020 | Test Acc: 0.7730\n",
            "[Epoch 150] Loss: 0.2083\n",
            "[Epoch 150] Val Acc: 0.8000 | Test Acc: 0.7710\n",
            "[Epoch 160] Loss: 0.2231\n",
            "[Epoch 160] Val Acc: 0.8020 | Test Acc: 0.7780\n",
            "[Epoch 170] Loss: 0.2086\n",
            "[Epoch 170] Val Acc: 0.8080 | Test Acc: 0.7740\n",
            "[Epoch 180] Loss: 0.1775\n",
            "[Epoch 180] Val Acc: 0.8060 | Test Acc: 0.7700\n",
            "[Epoch 190] Loss: 0.1850\n",
            "[Epoch 190] Val Acc: 0.8000 | Test Acc: 0.7680\n",
            "[Epoch 200] Loss: 0.1605\n",
            "[Epoch 200] Val Acc: 0.8020 | Test Acc: 0.7720\n",
            "\n",
            "---------- HyperGCN | Pubmed_labelnoise ----------\n",
            "[Epoch  10] Loss: 1.0389\n",
            "[Epoch  10] Val Acc: 0.3440 | Test Acc: 0.3600\n",
            "[Epoch  20] Loss: 0.9321\n",
            "[Epoch  20] Val Acc: 0.4760 | Test Acc: 0.4950\n",
            "[Epoch  30] Loss: 0.8044\n",
            "[Epoch  30] Val Acc: 0.6320 | Test Acc: 0.6180\n",
            "[Epoch  40] Loss: 0.6791\n",
            "[Epoch  40] Val Acc: 0.6780 | Test Acc: 0.6740\n",
            "[Epoch  50] Loss: 0.5754\n",
            "[Epoch  50] Val Acc: 0.6960 | Test Acc: 0.6920\n",
            "[Epoch  60] Loss: 0.4935\n",
            "[Epoch  60] Val Acc: 0.7180 | Test Acc: 0.7080\n",
            "[Epoch  70] Loss: 0.4469\n",
            "[Epoch  70] Val Acc: 0.7180 | Test Acc: 0.7110\n",
            "[Epoch  80] Loss: 0.3835\n",
            "[Epoch  80] Val Acc: 0.7240 | Test Acc: 0.7120\n",
            "[Epoch  90] Loss: 0.3214\n",
            "[Epoch  90] Val Acc: 0.7200 | Test Acc: 0.7100\n",
            "[Epoch 100] Loss: 0.3376\n",
            "[Epoch 100] Val Acc: 0.7140 | Test Acc: 0.6960\n",
            "[Epoch 110] Loss: 0.2882\n",
            "[Epoch 110] Val Acc: 0.7220 | Test Acc: 0.6990\n",
            "[Epoch 120] Loss: 0.2802\n",
            "[Epoch 120] Val Acc: 0.7280 | Test Acc: 0.7070\n",
            "[Epoch 130] Loss: 0.2680\n",
            "[Epoch 130] Val Acc: 0.7100 | Test Acc: 0.7010\n",
            "[Epoch 140] Loss: 0.2502\n",
            "[Epoch 140] Val Acc: 0.6980 | Test Acc: 0.6830\n",
            "[Epoch 150] Loss: 0.2495\n",
            "[Epoch 150] Val Acc: 0.7060 | Test Acc: 0.7030\n",
            "[Epoch 160] Loss: 0.2360\n",
            "[Epoch 160] Val Acc: 0.6980 | Test Acc: 0.6940\n",
            "[Epoch 170] Loss: 0.2263\n",
            "[Epoch 170] Val Acc: 0.6900 | Test Acc: 0.6830\n",
            "[Epoch 180] Loss: 0.2094\n",
            "[Epoch 180] Val Acc: 0.6820 | Test Acc: 0.6810\n",
            "[Epoch 190] Loss: 0.2059\n",
            "[Epoch 190] Val Acc: 0.6940 | Test Acc: 0.6890\n",
            "[Epoch 200] Loss: 0.1906\n",
            "[Epoch 200] Val Acc: 0.6980 | Test Acc: 0.6960\n",
            "Final Results:\n",
            "       Model                 Dataset  Train Acc @ Best Val  Best Val Acc  \\\n",
            "0        GCN                    Cora              0.992857         0.802   \n",
            "1        GCN      Cora_gaussiannoise              1.000000         0.560   \n",
            "2        GCN       Cora_perturbation              0.978571         0.780   \n",
            "3        GCN         Cora_labelnoise              0.971429         0.758   \n",
            "4        GCN                Citeseer              0.991667         0.724   \n",
            "5        GCN  Citeseer_gaussiannoise              0.983333         0.360   \n",
            "6        GCN   Citeseer_perturbation              0.966667         0.714   \n",
            "7        GCN     Citeseer_labelnoise              0.966667         0.664   \n",
            "8        GCN                  Pubmed              0.983333         0.804   \n",
            "9        GCN    Pubmed_gaussiannoise              0.966667         0.462   \n",
            "10       GCN     Pubmed_perturbation              0.983333         0.802   \n",
            "11       GCN       Pubmed_labelnoise              0.983333         0.738   \n",
            "12  HyperGCN                    Cora              0.950000         0.810   \n",
            "13  HyperGCN      Cora_gaussiannoise              1.000000         0.686   \n",
            "14  HyperGCN       Cora_perturbation              0.985714         0.798   \n",
            "15  HyperGCN         Cora_labelnoise              0.971429         0.772   \n",
            "16  HyperGCN                Citeseer              0.941667         0.714   \n",
            "17  HyperGCN  Citeseer_gaussiannoise              0.991667         0.442   \n",
            "18  HyperGCN   Citeseer_perturbation              0.891667         0.700   \n",
            "19  HyperGCN     Citeseer_labelnoise              0.908333         0.666   \n",
            "20  HyperGCN                  Pubmed              0.983333         0.804   \n",
            "21  HyperGCN    Pubmed_gaussiannoise              1.000000         0.572   \n",
            "22  HyperGCN     Pubmed_perturbation              0.983333         0.812   \n",
            "23  HyperGCN       Pubmed_labelnoise              0.916667         0.736   \n",
            "\n",
            "    Test Acc @ Best Val  \n",
            "0                 0.825  \n",
            "1                 0.545  \n",
            "2                 0.788  \n",
            "3                 0.750  \n",
            "4                 0.714  \n",
            "5                 0.352  \n",
            "6                 0.687  \n",
            "7                 0.683  \n",
            "8                 0.781  \n",
            "9                 0.413  \n",
            "10                0.777  \n",
            "11                0.720  \n",
            "12                0.802  \n",
            "13                0.693  \n",
            "14                0.805  \n",
            "15                0.760  \n",
            "16                0.699  \n",
            "17                0.438  \n",
            "18                0.680  \n",
            "19                0.665  \n",
            "20                0.778  \n",
            "21                0.564  \n",
            "22                0.765  \n",
            "23                0.720  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def extract_base_dataset(name):\n",
        "    return name.split('_')[0]\n",
        "\n",
        "def extract_aug_type(name):\n",
        "    if '_gaussiannoise' in name:\n",
        "        return 'Gaussian Noise'\n",
        "    elif '_perturbation' in name:\n",
        "        return 'Edge Perturbation'\n",
        "    elif '_labelnoise' in name:\n",
        "        return 'Label Noise'\n",
        "    else:\n",
        "        return 'Original'\n",
        "\n",
        "def plot_grouped_test_accuracy(df, dataset_name, save_path=\"test_accuracy_plot\"):\n",
        "    df = df.copy()\n",
        "\n",
        "    # 원하는 데이터셋만 필터링\n",
        "    df = df[df['Dataset'].str.startswith(dataset_name)]\n",
        "\n",
        "    df['Augmentation'] = df['Dataset'].apply(extract_aug_type)\n",
        "    df['Augmentation'] = pd.Categorical(\n",
        "        df['Augmentation'],\n",
        "        ['Original', 'Gaussian Noise', 'Edge Perturbation', 'Label Noise'],\n",
        "        ordered=True\n",
        "    )\n",
        "\n",
        "    df['Model'] = df['Model'].replace({'HyperGCN': 'HGCN'})\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(\n",
        "        data=df,\n",
        "        x=\"Augmentation\",\n",
        "        y=\"Test Acc @ Best Val\",\n",
        "        hue=\"Model\",\n",
        "        ci=\"sd\",\n",
        "        dodge=True\n",
        "    )\n",
        "\n",
        "    plt.title(f\"Test Accuracy on {dataset_name}\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"Perturbation Type\")\n",
        "    plt.legend(title=\"Model\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        save_path += \"_\" + dataset_name + \".png\"\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "plot_grouped_test_accuracy(df, 'Cora')\n",
        "plot_grouped_test_accuracy(df, 'Citeseer')\n",
        "plot_grouped_test_accuracy(df, 'Pubmed')"
      ],
      "metadata": {
        "id": "bwgmeSfbMOSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846f0241-bcc3-453c-cbeb-9d9ecfc34095"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ba763d2d7b98>:34: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar='sd'` for the same effect.\n",
            "\n",
            "  sns.barplot(\n",
            "<ipython-input-12-ba763d2d7b98>:34: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar='sd'` for the same effect.\n",
            "\n",
            "  sns.barplot(\n",
            "<ipython-input-12-ba763d2d7b98>:34: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar='sd'` for the same effect.\n",
            "\n",
            "  sns.barplot(\n"
          ]
        }
      ]
    }
  ]
}